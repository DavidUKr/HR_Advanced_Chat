{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a84e6225-d1d3-4fc0-ba8d-2352a058c58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved image: Imagine.jpg\n",
      "Image extraction complete.\n",
      "\n",
      "Page 1, Table 1 headers: ['region_id', 'region_name']\n",
      "Saved table: extracted_content\\Regions.csv, OK: 1\n",
      "Page 1, Table 2 headers: ['country_id', 'country_name', 'region_id']\n",
      "Saved table: extracted_content\\Countries.csv, OK: 1\n",
      "Page 2, Table 1 headers: ['location_id', 'street_address', 'postal_code', 'city', 'state_province', 'country_id']\n",
      "Saved table: extracted_content\\Locations.csv, OK: 1\n",
      "Page 3, Table 1 headers: ['department_id', 'department_name', 'manager_id', 'location_id']\n",
      "Saved table: extracted_content\\Departments.csv, OK: 1\n",
      "Page 4, Table 1 headers: ['job_id', 'job_title', 'min_salary', 'max_salary']\n",
      "Saved table: extracted_content\\Jobs.csv, OK: 1\n",
      "Page 5, Table 1 headers: ['employee_id', 'first_name', 'last_name', 'email', 'phone_number', 'hire_date', 'job_id', 'salary', 'commission_pct', 'manager_id', 'department_id']\n",
      "Saved table: extracted_content\\Employees.csv, OK: 1\n",
      "Page 6, Table 1 headers: ['132', 'TJ', 'Olson', 'TJOLSON', '650.124.8234', '10-APR-1999', 'ST_CLERK', '2100', 'NULL', '121', '50']\n",
      "Saved table: extracted_content\\Employees.csv, OK: 0\n",
      "Page 7, Table 1 headers: ['179', 'Charles', 'Johnson', 'CJOHNSON', '011.44.1644.429262', '04-JAN-2000', 'SA_REP', '6200', '.10', '149', '80']\n",
      "Saved table: extracted_content\\Employees.csv, OK: 0\n",
      "Table extraction complete.\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import io\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import pdfplumber\n",
    "import csv\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def extract_table_titles(pdf_path):\n",
    "    # Deschide PDF-ul\n",
    "    doc = fitz.open(pdf_path)\n",
    "    table_titles = []\n",
    "    title_frequencies = defaultdict(int)\n",
    "\n",
    "    # Variabilă pentru a ține evidența rândurilor goale între titlurile de tabele\n",
    "    blank_lines_count = 0\n",
    "    \n",
    "    # Parcurge fiecare pagină\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc.load_page(page_num)\n",
    "        text = page.get_text(\"text\")\n",
    "        lines = text.split('\\n')\n",
    "        \n",
    "        for line in lines:\n",
    "            words = line.split()\n",
    "            \n",
    "            # Verifică dacă linia este goală\n",
    "            if len(words) == 0:\n",
    "                blank_lines_count += 1\n",
    "            else:\n",
    "                # Verifică dacă linia conține un singur cuvânt care începe cu literă mare\n",
    "                if len(words) == 1 and words[0][0].isupper():\n",
    "                    # Pentru primul titlu de tabel, nu este nevoie să verificăm numărul de rânduri goale\n",
    "                    if not table_titles or blank_lines_count >= 2:\n",
    "                        table_titles.append(words[0])\n",
    "                        title_frequencies[words[0]] = 0\n",
    "                    blank_lines_count = 0  # Resetează contorul de rânduri goale\n",
    "                else:\n",
    "                    # Resetează contorul de rânduri goale dacă întâlnește o linie care nu este goală sau nu este titlu de tabel\n",
    "                    blank_lines_count = 0\n",
    "\n",
    "    return table_titles, dict(title_frequencies)\n",
    "    \n",
    "def extract_images_from_pdf(pdf_path, output_folder):\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "    \n",
    "    for page_num in range(len(pdf_document)):\n",
    "        page = pdf_document.load_page(page_num)\n",
    "        image_list = page.get_images(full=True)\n",
    "\n",
    "        for img_index, img in enumerate(image_list):\n",
    "            xref = img[0]\n",
    "            base_image = pdf_document.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "\n",
    "            image = Image.open(io.BytesIO(image_bytes))\n",
    "            image_path = os.path.join(f\"Imagine.jpg\")\n",
    "            image.save(image_path)\n",
    "\n",
    "            print(f\"Saved image: {image_path}\")\n",
    "\n",
    "    print(\"Image extraction complete.\")\n",
    "    img = Image.open('Imagine.jpg')\n",
    "    text = pytesseract.image_to_string(img)\n",
    "    print(text)\n",
    "\n",
    "\n",
    "def normalize_header(header):\n",
    "    \"\"\"Normalizează header-ul eliminând spațiile și caracterele de nouă linie.\"\"\"\n",
    "   # header=header.rstrip('\\n')\n",
    "    # header.replace('\\n',\"\").strip()\n",
    "    for df in header.columns:\n",
    "        df=df.replace('\\n','').strip()\n",
    "    return header#header.replace('\\n','').strip()\n",
    "\n",
    "def extract_tables_from_pdf(pdf_path, output_folder):\n",
    "    table_titles, title_frequencies = extract_table_titles(pdf_path)\n",
    "    index=0\n",
    "    all_tables_df = pd.DataFrame()\n",
    "    # Cuvinte cheie de verificat în antetul tabelului (normalizate)\n",
    "    keywords = {\"region_id\", \"country_id\", \"location_id\", \"job_id\"}\n",
    "    \n",
    "    # Creează directorul de ieșire dacă nu există\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page_num, page in enumerate(pdf.pages):\n",
    "            tables = page.extract_tables()\n",
    "\n",
    "            for table_index, table in enumerate(tables):\n",
    "                # Creează DataFrame din tabel\n",
    "                if len(table) > 1:\n",
    "                    df = pd.DataFrame(table[1:], columns=table[0])\n",
    "                else:\n",
    "                    continue  # Sari peste tabelele fără date\n",
    "                \n",
    "                # Normalizează antetul\n",
    "                headers = [header for header in df.columns] #{normalize_header(header) for header in df.columns} # [header for header in df.columns] \n",
    "                #df=normalize_header(df)\n",
    "                #headers2=[header for header in df.columns] \n",
    "                print(f\"Page {page_num + 1}, Table {table_index + 1} headers: {headers}\")\n",
    "                \n",
    "                # Verifică dacă antetul conține toate cuvintele cheie\n",
    "                ok = 0\n",
    "                for keyword in keywords:\n",
    "                    if keyword in headers:\n",
    "                        ok = 1\n",
    "                        break\n",
    "\n",
    "                if ok == 1:\n",
    "                    # Construiește calea fișierului folosind os.path.join\n",
    "                    table_path = os.path.join(output_folder, f\"{table_titles[index]}.csv\")\n",
    "                    index=index+1\n",
    "                    #df2=df\n",
    "                    df.to_csv(table_path, index=False)\n",
    "                    if all_tables_df.empty:\n",
    "                            all_tables_df = df\n",
    "                    else:\n",
    "                            all_tables_df = pd.concat([all_tables_df, df], ignore_index=True)\n",
    "                    \n",
    "                    \n",
    "                else: \n",
    "                    previous_table_path = os.path.join(output_folder, f\"{table_titles[index - 1]}.csv\")\n",
    "                    df_existent = pd.read_csv(previous_table_path)\n",
    "                    df_existent = pd.concat([df_existent, df], ignore_index=True)\n",
    "                    df_existent.to_csv(previous_table_path, index=False)\n",
    "                    all_tables_df = df_existent\n",
    "    \n",
    "\n",
    "                \n",
    "                print(f\"Saved table: {table_path}, OK: {ok}\")\n",
    "   \n",
    "    print(\"Table extraction complete.\")\n",
    "    \n",
    "# Example usage\n",
    "pdf_path = 'Employee-details-1.pdf'  # Path to your PDF file\n",
    "output_folder = 'extracted_content'  # Output folder to save images and tables\n",
    "\n",
    "import os\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "# ok\n",
    "extract_images_from_pdf(pdf_path, output_folder)\n",
    "extract_tables_from_pdf(pdf_path, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "555b3723-f582-4302-a439-12359e1413e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "# Set the tesseract executable path\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "# Example usageemployee_details.pdf\n",
    "img = Image.open('Imagine.jpg')\n",
    "text = pytesseract.image_to_string(img)\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc1923d9-a461-49b6-849f-4dcd75c6ec57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   employee_id first_name last_name     email  phone_number    hire_date  \\\n",
      "0        100.0     Steven      King     SKING  515.123.4567  17-JUN-1987   \n",
      "1        101.0      Neena   Kochhar  NKOCHHAR  515.123.4568  21-SEP-1989   \n",
      "2        102.0        Lex   De Haan   LDEHAAN  515.123.4569  13-JAN-1993   \n",
      "3        103.0  Alexander    Hunold   AHUNOLD  590.423.4567  03-JAN-1990   \n",
      "4        104.0      Bruce     Ernst    BERNST  590.423.4568  21-MAY-1991   \n",
      "\n",
      "    job_id   salary  commission_pct  manager_id  ...  Charles  Johnson  \\\n",
      "0  AD_PRES  24000.0             NaN         NaN  ...      NaN      NaN   \n",
      "1    AD_VP  17000.0             NaN       100.0  ...      NaN      NaN   \n",
      "2    AD_VP  17000.0             NaN       100.0  ...      NaN      NaN   \n",
      "3  IT_PROG   9000.0             NaN       102.0  ...      NaN      NaN   \n",
      "4  IT_PROG   6000.0             NaN       103.0  ...      NaN      NaN   \n",
      "\n",
      "  CJOHNSON 011.44.1644.429262 04-JAN-2000 SA_REP 6200 .10  149  80  \n",
      "0      NaN                NaN         NaN    NaN  NaN NaN  NaN NaN  \n",
      "1      NaN                NaN         NaN    NaN  NaN NaN  NaN NaN  \n",
      "2      NaN                NaN         NaN    NaN  NaN NaN  NaN NaN  \n",
      "3      NaN                NaN         NaN    NaN  NaN NaN  NaN NaN  \n",
      "4      NaN                NaN         NaN    NaN  NaN NaN  NaN NaN  \n",
      "\n",
      "[5 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the provided CSV file\n",
    "csv_path = r\"C:/Users/Talent2/Desktop/ness/extracted_content/Employees.csv\"\n",
    "df_existent = pd.read_csv(csv_path)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(df_existent.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04030076-7846-4e44-a81b-ceb30c6acc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "cale_fisier_csv = os.path.join(output_folder, f\"{table_titles[index-1]}.csv\")\n",
    "                    # Încărcați datele din fișierul CSV existent într-un DataFrame\n",
    "                    df_existent = pd.read_csv(cale_fisier_csv)\n",
    "                    # Adăugați tabelul extras la DataFrame-ul existent\n",
    "                    df2 = pd.concat([df2, df], ignore_index=True)\n",
    "                    # Salvați DataFrame-ul final în fișierul CSV existent\n",
    "                    df_final=df2\n",
    "                    df_final.to_csv(cale_fisier_csv, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
