{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a84e6225-d1d3-4fc0-ba8d-2352a058c58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved image: extracted_content/page_10img1.png\n",
      "Image extraction complete.\n",
      "Page 1, Table 1 headers: {'region_id', 'region_name'}\n",
      "Saved table: extracted_content\\Regions.csv, OK: 1\n",
      "Page 1, Table 2 headers: {'country_id', 'region_id', 'country_name'}\n",
      "Saved table: extracted_content\\Countries.csv, OK: 1\n",
      "Page 2, Table 1 headers: {'street_address', 'city', 'state_province', 'location_id', 'country_id', 'postal_code'}\n",
      "Saved table: extracted_content\\Locations.csv, OK: 1\n",
      "Page 3, Table 1 headers: {'department_id', 'location_id', 'manager_id', 'department_name'}\n",
      "Saved table: extracted_content\\Departments.csv, OK: 1\n",
      "Page 4, Table 1 headers: {'job_title', 'max_salary', 'job_id', 'min_salary'}\n",
      "Saved table: extracted_content\\Jobs.csv, OK: 1\n",
      "Page 4, Table 2 headers: {'department_id', 'last_name', 'employee_id', 'phone_number', 'hire_date', 'email', 'salary', 'job_id', 'commission_pct', 'first_name', 'manager_id'}\n",
      "Saved table: extracted_content\\Employees.csv, OK: 1\n",
      "Page 5, Table 1 headers: {'Bruce', 'BERNST', '60', '104', '21-MAY-1991', '6000', '103', 'NULL', 'Ernst', 'IT_PROG', '590.423.4568'}\n",
      "Saved table: extracted_content\\Employees.csv, OK: 0\n",
      "Page 6, Table 1 headers: {'ST_MAN', '6500', '100', '123', '50', '10-OCT-1997', 'Shanta', 'SVOLLMAN', 'Vollman', '650.123.4234', 'NULL'}\n",
      "Saved table: extracted_content\\Employees.csv, OK: 0\n",
      "Page 7, Table 1 headers: {'3100', 'Davies', '29-JAN-1997', 'CDAVIES', 'ST_CLERK', '650.121.2994', 'Curtis', '50', '124', 'NULL', '142'}\n",
      "Saved table: extracted_content\\Employees.csv, OK: 0\n",
      "Page 8, Table 1 headers: {'OTUVAULT', '7000', '155', '145', 'SA_REP', '.15', 'Oliver', 'Tuvault', '80', '23-NOV-1999', '011.44.1344.486508'}\n",
      "Saved table: extracted_content\\Employees.csv, OK: 0\n",
      "Page 9, Table 1 headers: {'148', '11500', 'Lisa', '168', '011.44.1343.929268', '11-MAR-1997', 'LOZER', '.25', '80', 'SA_REP', 'Ozer'}\n",
      "Saved table: extracted_content\\Employees.csv, OK: 0\n",
      "Page 10, Table 1 headers: {'120', '3100', '23-FEB-1998', '181', 'Fleaur', 'Jean', '50', 'SH_CLERK', 'JFLEAUR', '650.507.9877', 'NULL'}\n",
      "Saved table: extracted_content\\Employees.csv, OK: 0\n",
      "Table extraction complete.\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import io\n",
    "from PIL import Image\n",
    "import pdfplumber\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "def extract_table_titles(pdf_path):\n",
    "    # Deschide PDF-ul\n",
    "    doc = fitz.open(pdf_path)\n",
    "    table_titles = []\n",
    "    title_frequencies = defaultdict(int)\n",
    "\n",
    "    # Variabilă pentru a ține evidența rândurilor goale între titlurile de tabele\n",
    "    blank_lines_count = 0\n",
    "    \n",
    "    # Parcurge fiecare pagină\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc.load_page(page_num)\n",
    "        text = page.get_text(\"text\")\n",
    "        lines = text.split('\\n')\n",
    "        \n",
    "        for line in lines:\n",
    "            words = line.split()\n",
    "            \n",
    "            # Verifică dacă linia este goală\n",
    "            if len(words) == 0:\n",
    "                blank_lines_count += 1\n",
    "            else:\n",
    "                # Verifică dacă linia conține un singur cuvânt care începe cu literă mare\n",
    "                if len(words) == 1 and words[0][0].isupper():\n",
    "                    # Pentru primul titlu de tabel, nu este nevoie să verificăm numărul de rânduri goale\n",
    "                    if not table_titles or blank_lines_count >= 2:\n",
    "                        table_titles.append(words[0])\n",
    "                        title_frequencies[words[0]] = 0\n",
    "                    blank_lines_count = 0  # Resetează contorul de rânduri goale\n",
    "                else:\n",
    "                    # Resetează contorul de rânduri goale dacă întâlnește o linie care nu este goală sau nu este titlu de tabel\n",
    "                    blank_lines_count = 0\n",
    "\n",
    "    return table_titles, dict(title_frequencies)\n",
    "    \n",
    "def extract_images_from_pdf(pdf_path, output_folder):\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "    \n",
    "    for page_num in range(len(pdf_document)):\n",
    "        page = pdf_document.load_page(page_num)\n",
    "        image_list = page.get_images(full=True)\n",
    "\n",
    "        for img_index, img in enumerate(image_list):\n",
    "            xref = img[0]\n",
    "            base_image = pdf_document.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "\n",
    "            image = Image.open(io.BytesIO(image_bytes))\n",
    "            image_path = f\"{output_folder}/page_{page_num + 1}img{img_index + 1}.{image.format.lower()}\"\n",
    "            image.save(image_path)\n",
    "\n",
    "            print(f\"Saved image: {image_path}\")\n",
    "\n",
    "    print(\"Image extraction complete.\")\n",
    "\n",
    "\n",
    "def normalize_header(header):\n",
    "    \"\"\"Normalizează header-ul eliminând spațiile și caracterele de nouă linie.\"\"\"\n",
    "   # header=header.rstrip('\\n')\n",
    "    # header.replace('\\n',\"\").strip()\n",
    "    return header.replace('\\n',\"\").strip()\n",
    "\n",
    "def extract_tables_from_pdf(pdf_path, output_folder):\n",
    "    table_titles, title_frequencies = extract_table_titles(pdf_path)\n",
    "    index=0\n",
    "    # Cuvinte cheie de verificat în antetul tabelului (normalizate)\n",
    "    keywords = {\"region_id\", \"country_id\", \"location_id\", \"job_id\"}\n",
    "    \n",
    "    # Creează directorul de ieșire dacă nu există\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page_num, page in enumerate(pdf.pages):\n",
    "            tables = page.extract_tables()\n",
    "\n",
    "            for table_index, table in enumerate(tables):\n",
    "                # Creează DataFrame din tabel\n",
    "                if len(table) > 1:\n",
    "                    df = pd.DataFrame(table[1:], columns=table[0])\n",
    "                else:\n",
    "                    continue  # Sari peste tabelele fără date\n",
    "                \n",
    "                # Normalizează antetul\n",
    "                headers = {normalize_header(header) for header in df.columns} # [header for header in df.columns] \n",
    "                #headers2=[header for header in df.columns] \n",
    "                print(f\"Page {page_num + 1}, Table {table_index + 1} headers: {headers}\")\n",
    "                \n",
    "                # Verifică dacă antetul conține toate cuvintele cheie\n",
    "                ok = 0\n",
    "                for keyword in keywords:\n",
    "                    if keyword in headers:\n",
    "                        ok = 1\n",
    "                        break\n",
    "\n",
    "                if ok == 1:\n",
    "                    # Construiește calea fișierului folosind os.path.join\n",
    "                    table_path = os.path.join(output_folder, f\"{table_titles[index]}.csv\")\n",
    "                    index=index+1\n",
    "                    df.to_csv(table_path, index=False)\n",
    "                else: \n",
    "                    cale_fisier_csv = os.path.join(output_folder, f\"{table_titles[index-1]}.csv\")\n",
    "                    # Încărcați datele din fișierul CSV existent într-un DataFrame\n",
    "                    df_existent = pd.read_csv(cale_fisier_csv)\n",
    "                    # Adăugați tabelul extras la DataFrame-ul existent\n",
    "                    df_final = pd.concat([df_existent, df], ignore_index=True)\n",
    "                    # Salvați DataFrame-ul final în fișierul CSV existent\n",
    "                    df_final.to_csv(cale_fisier_csv, index=False)\n",
    "\n",
    "                print(f\"Saved table: {table_path}, OK: {ok}\")\n",
    "\n",
    "    print(\"Table extraction complete.\")\n",
    "    \n",
    "# Example usage\n",
    "pdf_path = 'employee_details.pdf'  # Path to your PDF file\n",
    "output_folder = 'extracted_content'  # Output folder to save images and tables\n",
    "\n",
    "import os\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "# ok\n",
    "extract_images_from_pdf(pdf_path, output_folder)\n",
    "extract_tables_from_pdf(pdf_path, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "555b3723-f582-4302-a439-12359e1413e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About Me\n",
      "\n",
      "Lorem ipsum dolor sit amet,\n",
      "consectetur adipiscing elit.\n",
      "Vestibulum sit amet quam\n",
      "rhoncus, egestas dui eget,\n",
      "malesuada justo. Ut aliquam\n",
      "augue.\n",
      "\n",
      "eg +123-456-7890\n",
      "@ hello@reallygreatsite.com\n",
      "6 123 Anywhere St., Any City\n",
      "\n",
      "LANGUAGE\n",
      "\n",
      "« English\n",
      "« Germany (basic)\n",
      "\n",
      "¢ Spain (basic)\n",
      "\n",
      "EXPERTISE\n",
      "\n",
      "* Management Skills\n",
      "¢ Creativity\n",
      "\n",
      "¢ Digital Marketing\n",
      "* Negotiation\n",
      "Critical Thinking\n",
      "Leadership\n",
      "\n",
      "RICHARD\n",
      "\n",
      "SANCHEZ\n",
      "\n",
      "Product Designer\n",
      "\n",
      "EXPERIEN\n",
      "\n",
      "Studio Showde\n",
      "\n",
      "Canberra - Australia\n",
      "\n",
      "2020 - 2022\n",
      "\n",
      "Lorem ipsum dolor sit amet, consectetur adipiscing elit.\n",
      "Vestibulum sit amet quam rhoncus, egestas dui eget,\n",
      "malesuada justo. Ut aliquam augue.\n",
      "\n",
      "Elsetown Cor.\n",
      "\n",
      "Kota Baru - Singapore\n",
      "\n",
      "2016 - 2020\n",
      "\n",
      "Lorem ipsum dolor sit amet, consectetur adipiscing elit.\n",
      "Vestibulum sit amet quam rhoncus, egestas dui eget,\n",
      "malesuada justo. Ut aliquam augue.\n",
      "\n",
      "Studio Showde\n",
      "\n",
      "sydney - Australia\n",
      "\n",
      "2010 - 2015\n",
      "\n",
      "Lorem ipsum dolor sit amet, consectetur adipiscing elit.\n",
      "Vestibulum sit amet quam rhoncus, egestas dui eget,\n",
      "malesuada justo. Ut aliquam augue.\n",
      "\n",
      "EDUCATION\n",
      "\n",
      "Borcelle University\n",
      "Bachelor of Business Management\n",
      "2014-2023\n",
      "\n",
      "Borcelle University\n",
      "\n",
      "Master of Business Management\n",
      "2014-2018\n",
      "\n",
      "SKILLS SUMMARY\n",
      "\n",
      "Design Process om 78 %\n",
      "\n",
      "Project Management one= 8] % yy\n",
      "\n",
      "NS\n",
      "\n",
      "Ws\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "# Set the tesseract executable path\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "# Example usageemployee_details.pdf\n",
    "img = Image.open('img.jpg')\n",
    "text = pytesseract.image_to_string(img)\n",
    "print(text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
